{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': 0.999992, 'word': 'Barack Obama', 'start': 0, 'end': 12}, {'entity_group': 'LOC', 'score': 0.9999887, 'word': 'Hawaii', 'start': 25, 'end': 31}, {'entity_group': 'ORG', 'score': 0.999961, 'word': 'Google', 'start': 43, 'end': 49}, {'entity_group': 'LOC', 'score': 0.98065805, 'word': 'Urbana Champaugn', 'start': 51, 'end': 67}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "model_checkpoint = \"xlm-roberta-large-finetuned-conll03-english\"\n",
    "set_seed(42)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "\n",
    "nlp = pipeline(\"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\")\n",
    "text = \"Barack Obama was born in Hawaii, and likes Google. Urbana Champaugn is a good place\"\n",
    "entities = nlp(text)#[0]['entity_group']\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Barack Obama was born in Hawaii, and likes Google. Urbana Champaugn is a good place', 'entities': [{'entity_group': 'PER', 'score': 0.999992, 'word': 'Barack Obama', 'start': 0, 'end': 12}, {'entity_group': 'LOC', 'score': 0.9999887, 'word': 'Hawaii', 'start': 25, 'end': 31}, {'entity_group': 'ORG', 'score': 0.999961, 'word': 'Google', 'start': 43, 'end': 49}, {'entity_group': 'LOC', 'score': 0.98065805, 'word': 'Urbana Champaugn', 'start': 51, 'end': 67}], 'labels': ['PER', 'LOC', 'ORG']}\n"
     ]
    }
   ],
   "source": [
    "labels = set([entity[\"entity_group\"] for entity in entities])\n",
    "print({\"text\": text, \"entities\": entities, \"labels\": list(labels)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified_html = \"\"\n",
    "    # for word in words:\n",
    "    #   if word == \"he\":\n",
    "    #     modified_html += \"<span style='background-color: purple;'>\" + word + \"</span> \"\n",
    "    #   else:\n",
    "    #     modified_html += word + \" \"\n",
    "    # return modified_html \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_entities(text, entities):\n",
    "    color_map = {\n",
    "        \"PER\": \"blue\",\n",
    "        \"LOC\": \"green\",\n",
    "        \"ORG\": \"red\"\n",
    "    }\n",
    "    new_text = \"\"\n",
    "    last_end = 0\n",
    "    for entity in entities:\n",
    "        label = entity[\"entity_group\"]\n",
    "        start = entity[\"start\"]\n",
    "        end = entity[\"end\"]\n",
    "        new_text += text[last_end:start]\n",
    "        color = color_map.get(label, \"black\")\n",
    "        new_text += f'<span style=\"color: {color};\">{text[start:end]}</span>'\n",
    "        last_end = end\n",
    "    new_text += text[last_end:]\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span style=\"color: blue;\">Barack Obama</span> was born in <span style=\"color: green;\">Hawaii</span>, and likes <span style=\"color: red;\">Google</span>. <span style=\"color: green;\">Urbana Champaugn</span> is a good place\n"
     ]
    }
   ],
   "source": [
    "entities = nlp(text)\n",
    "new_text = highlight_entities(text, entities)\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'LABEL_0', 'score': 0.57435954, 'index': 1, 'word': 'Apple', 'start': 0, 'end': 5}, {'entity': 'LABEL_0', 'score': 0.5643061, 'index': 2, 'word': 'is', 'start': 6, 'end': 8}, {'entity': 'LABEL_0', 'score': 0.5997141, 'index': 3, 'word': 'looking', 'start': 9, 'end': 16}, {'entity': 'LABEL_1', 'score': 0.5410624, 'index': 4, 'word': 'at', 'start': 17, 'end': 19}, {'entity': 'LABEL_0', 'score': 0.51501936, 'index': 5, 'word': 'buying', 'start': 20, 'end': 26}, {'entity': 'LABEL_0', 'score': 0.680543, 'index': 6, 'word': 'U', 'start': 27, 'end': 28}, {'entity': 'LABEL_0', 'score': 0.612117, 'index': 7, 'word': '.', 'start': 28, 'end': 29}, {'entity': 'LABEL_0', 'score': 0.57498014, 'index': 8, 'word': 'K', 'start': 29, 'end': 30}, {'entity': 'LABEL_0', 'score': 0.59091127, 'index': 9, 'word': '.', 'start': 30, 'end': 31}, {'entity': 'LABEL_0', 'score': 0.51981264, 'index': 10, 'word': 'start', 'start': 32, 'end': 37}, {'entity': 'LABEL_0', 'score': 0.6103272, 'index': 11, 'word': '##up', 'start': 37, 'end': 39}, {'entity': 'LABEL_1', 'score': 0.5471513, 'index': 12, 'word': 'for', 'start': 40, 'end': 43}, {'entity': 'LABEL_0', 'score': 0.6017145, 'index': 13, 'word': '$', 'start': 44, 'end': 45}, {'entity': 'LABEL_0', 'score': 0.56842387, 'index': 14, 'word': '1', 'start': 45, 'end': 46}, {'entity': 'LABEL_0', 'score': 0.63756925, 'index': 15, 'word': 'billion', 'start': 47, 'end': 54}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline(\"ner\", model=\"bert-base-cased\", tokenizer=\"bert-base-cased\")\n",
    "\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "\n",
    "entities = ner(text)\n",
    "print(entities)\n",
    "#for ent in entities:\n",
    " #   if ent[\"entity\"] != \"O\":\n",
    "  #      start = ent[\"start\"]\n",
    "   #     end = ent[\"end\"]\n",
    "    #    entity_type = ent[\"entity\"]\n",
    "     #   print(f\"{entity_type}: {text[start:end]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Barack Obama<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> was born in <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">Hawaii<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">LOC</span></span>, and likes <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">Google<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ORG</span></span>. <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">Urbana Champaugn<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">LOC</span></span> is a good place</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">',\n",
       " '',\n",
       " '<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">',\n",
       " 'Barack Obama',\n",
       " '<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">',\n",
       " 'PER',\n",
       " '</span>',\n",
       " '</span>',\n",
       " ' was born in ',\n",
       " '<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">',\n",
       " 'Hawaii',\n",
       " '<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">',\n",
       " 'LOC',\n",
       " '</span>',\n",
       " '</span>',\n",
       " ', and likes ',\n",
       " '<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">',\n",
       " 'Google',\n",
       " '<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">',\n",
       " 'ORG',\n",
       " '</span>',\n",
       " '</span>',\n",
       " '. ',\n",
       " '<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">',\n",
       " 'Urbana Champaugn',\n",
       " '<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">',\n",
       " 'LOC',\n",
       " '</span>',\n",
       " '</span>',\n",
       " ' is a good place',\n",
       " '</div>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipymarkup import show_span_ascii_markup, show_dep_ascii_markup\n",
    "from ipymarkup import show_span_box_markup\n",
    "from ipymarkup.palette import palette, BLUE, RED, GREEN\n",
    "from ipymarkup import format_span_box_markup\n",
    "\n",
    "\n",
    "text = 'Barack Obama was born in Hawaii, and likes Google. Urbana Champaugn is a good place'\n",
    "\n",
    "spans = []\n",
    "for entity in entities:\n",
    "    #     label = entity[\"entity_group\"]\n",
    "    #     start = entity[\"start\"]\n",
    "    #     end = entity[\"end\"]\n",
    "    #     new_text += text[last_end:start]\n",
    "    #     color = color_map.get(label, \"black\")\n",
    "    #     new_text += f'<span style=\"color: {color};\">{text[start:end]}</span>'\n",
    "    #     last_end = end\n",
    "    # new_text += text[last_end:\n",
    "    spans.append((entity[\"start\"], entity[\"end\"], entity[\"entity_group\"]))\n",
    "\n",
    "#show_span_ascii_markup(text, spans)\n",
    "\n",
    "show_span_box_markup(text, spans, palette=palette(PER=BLUE, ORG=RED, LOC=GREEN))\n",
    "\n",
    "list(format_span_box_markup(text, spans))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88b0272d80acab83776fd72d1a9b5c7096c825809c4fd3f61ad7b313653bb5a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
